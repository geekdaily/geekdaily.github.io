
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>
      
        LiveBlog: Hadoop Operations - 
      
      geek!daily
    </title>
    
    <meta name="author" content="Jim Meyer">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <!-- HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <link href="/assets/themes/hooligan/bootstrap/css/bootstrap.min.css" rel="stylesheet">
    <link href="/assets/themes/hooligan/bootstrap/css/bootstrap-responsive.min.css" rel="stylesheet">
    <link rel="stylesheet" type="text/css" href="/assets/themes/hooligan/css-social-buttons/css/zocial.stripped.css">
    <link href="/assets/themes/hooligan/css/pygments.css" rel="stylesheet" type="text/css" media="all">
    <link href="/assets/themes/hooligan/css/darkstrap.css" rel="stylesheet" type="text/css" media="all">
    <link href="/assets/themes/hooligan/css/style.css?body=1" rel="stylesheet" type="text/css" media="all">

    <!-- fav and touch icons -->
    <!-- Update these with your own images
      <link rel="shortcut icon" href="images/favicon.ico">
      <link rel="apple-touch-icon" href="images/apple-touch-icon.png">
      <link rel="apple-touch-icon" sizes="72x72" href="images/apple-touch-icon-72x72.png">
      <link rel="apple-touch-icon" sizes="114x114" href="images/apple-touch-icon-114x114.png">
    -->
  </head>

  <body>
    <div id="page-wrap">
      <div class="navbar">
        <div class="navbar-inner">
          <div class="container">
            <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
            <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </a>

            <a class="brand" href="/">geek!daily</a>

            <div class="nav-collapse">
              <ul class="nav">
                
                
                


  
    
      
    
  
    
      
      	
      	<li><a href="/archive.html">Archive</a></li>
      	
      
    
  
    
      
    
  
    
      
      	
      	<li><a href="/categories.html">Categories</a></li>
      	
      
    
  
    
      
    
  
    
      
      	
      	<li><a href="/pages.html">Pages</a></li>
      	
      
    
  
    
      
    
  
    
      
    
  
    
      
      	
      	<li><a href="/tags.html">Tags</a></li>
      	
      
    
  



              </ul>
              <ul class="nav pull-right social visible-desktop">
                <li class="divider-vertical"></li>
                
                <li>
                  <a href="https://github.com/purp" class="zocial github icon" target="_blank">
                    <span class="hidden-desktop">Github</span>
                  </a>
                </li>
                
                
                
                <li>
                  <a href="https://twitter.com/purp" class="zocial twitter icon" target="_blank">
                    <span class="hidden-desktop">Twitter</span>
                  </a>
                </li>
                
                
                
                <li>
                  <a href="http://www.linkedin.com/in/jimmeyer" class="zocial linkedin icon" target="_blank">
                    <span class="hidden-desktop">LinkedIn</span>
                  </a>
                </li>
                
                
                <li>
                  <a href="http://feeds.feedburner.com/geekdailyblog" class="zocial rss icon" target="_blank">
                    <span class="hidden-desktop">FeedBurner</span>
                  </a>
                </li>
                
              </ul>
            </div>
          </div>
        </div>
      </div>

      <div class="container">
        <div class="content">
          
<div class="page-header">
  <h1>
    LiveBlog: Hadoop Operations 
    
  </h1>
</div>

<div class="row">
  <div class="span8">
    <p>I’m at Velocity 2009, sitting in on the “Hadoop Operations” talk.</p>

<p>Jeff Hammerbacher, Chief Scientist, Cloudera (email is first six of his last name at his company dot com). He has an ambitious agenda for this session and talks very fast, so sketchy notes and abbrevs for me. Pardon the crappy formatting.</p>

<p>slides are <a href="http://www.slideshare.net/jhammerb/20090622-velocity">here</a>.</p>

<p>Built data team at FB. ~30 ppl when he left. Built Hive and Cassandra.</p>

<p>Good resources:</p>

<ul>
  <li>“Hadoop: The Definitive Guide” by Tom White (must have)</li>
  <li>“Hadoop Cluster Management” slides by Marco Nicosia’s 2009 USENIX talk</li>
</ul>

<p>Hadoop: OSS for WSCs (warehouse-scale computers)</p>

<p>Typical cluster: 1U 2×4 core, 8GB RAM, 4×1TB SATA, 2×1 gE NIC; one switch per rack with 8 Gb intfc to backbone. Think 40-node-rack as unit.</p>

<p>HDFS: breaks files to 128MB, replicates blocks across nodes. W1RM design. checksumming, replication, compression included (tell you three times). Hooks in via Java, C, command line tools, FUSE, WebDAV, Thrift. Not usually mounted directly.</p>

<p>[how does it handle many small files? see HAR files below, see Common problems below, no statements about performance]</p>

<p>HDFS looks to diversly write blocks (across racks) using topology info.</p>

<p>MapReduce uses HDFS api to assign work to where the data is.</p>

<p>Avro: cross-language serialization for on-wire/RPC and persistence, includes versioning and security</p>

<p>HBase: Google’s BigTable lookalike on top of HDFS</p>

<p>Hive: SQL-like interface to structured data stored in HDFS. Replace DWH.</p>

<p>Pig: lang for dataflow programming.</p>

<p>Zookeeper: manage a distributed system</p>

<h3 id="good-ways-to-dip-your-toes-with-hadoop">Good ways to dip your toes with Hadoop:</h3>

<p><em>Projects:</em></p>

<ul>
  <li>Log or msg warehouse</li>
  <li>DB archival store</li>
  <li>ETL for DWH</li>
  <li>Search team projects (autocomplete, did you mean, indexing)</li>
  <li>Targeted web crawls (market research, etc)</li>
</ul>

<p><em>Clusters:</em></p>

<ul>
  <li>use retired DB servers</li>
  <li>use unused desktops</li>
  <li>use EC2</li>
</ul>

<p>[skipped a lot about how the project runs, apache voting, etc.]</p>

<p>Don’t run Hadoop across two data centers; one per and communicate at the app layer. [this sounds a lot like the rules for MPI et al ca. 1999-2000]</p>

<p>Make sure to use ECC RAM. High volume mem churn requires it.</p>

<p>Linux/CentOS “mildly preferred”</p>

<p>Mount local FS “noatime” for performance.</p>

<p>Recommend ext3 over xfs. Local FS performance improvements (e.g. xfs) don’t necessarily translate to global perf improvements (network bottlenecks consume it). Mentioned an xfs long-write problem.</p>

<p>JBOD over RAID0; slightly better performance and losing a disk doesn’t suck as much.</p>

<p>Java 6 update 14 or later (update 14 makes 64-bit pointers as cheap as 32-bit).</p>

<h3 id="installation-httpwwwclouderacomhadoop">Installation: http://www.cloudera.com/hadoop</h3>

<p>“In our distribution we put [things] where they ought to be.” Register with init.d, etc.</p>

<h3 id="configuration-httpmyclouderacom">Configuration: http://my.cloudera.com/</h3>

<p>You spec topology and whether JT/NN live on same machine, it spits out the rest. Hangs on to it for you, too.</p>

<h4 id="config-modes">Config modes</h4>

<p>Standalone mode:</p>

<ul>
  <li>Everything in one JVM</li>
  <li>Only one reducer, so you might not be able to find the bug</li>
</ul>

<p>Pseudo-dist mode:</p>

<ul>
  <li>All daemons on one box using socket IPC</li>
</ul>

<p>Dist mode:</p>

<ul>
  <li>For production</li>
</ul>

<h4 id="config-files">Config files</h4>

<ul>
  <li>xml based</li>
  <li>org.apache.hadoop.conf has Configuration class</li>
  <li>Later resources overwrite earlier; “final” keyword prevents overwrite</li>
  <li>common-site.xml, hdfs-site.xml, mapred-site.xml</li>
  <li>Look in .template for examples</li>
</ul>

<p>Cloudera admins their soft-layer cluster with Puppet “with varying level of success”. He’s seen Chef, cfengine, bcfg2, and others.</p>

<h4 id="problems-in-config">Problems in config:</h4>

<ul>
  <li>“The problem is almost always DNS”—Todd Lipcon</li>
  <li>Open the necessary ports (many) in firewall</li>
  <li>Disting ssh keys (Cloudera uses expect)</li>
  <li>directory permissions (writing logs)</li>
  <li>Use all your disks!</li>
  <li>Don’t try to use NFS for large clusters</li>
  <li>JAVA_HOME set right (esp. on Macs)</li>
</ul>

<p>Nehalems ~2x performance improvement</p>

<h3 id="hdfs-namenode-the-master">HDFS NameNode (“the master”)</h3>

<p>VERSION file specs layoutVersion (negative number, decrements for each new). You hope this doesn’t change much; upgrade is painful</p>

<p>NN manages fs image (inode map, in mem) and edit log (journal, to disk).</p>

<p>Secondary NN (on different node) aka checkpoint node (v0.21): replays journal and tells primary to forget some history to prevent the edit log from becoming ridiculously large.</p>

<p>Backup node: write same data to NFS to recover if local node blows up</p>

<h3 id="datanode-round-robins-blocks-across-all-nodes">DataNode: round-robins blocks across all nodes.</h3>

<ul>
  <li>Heartbeats to the nodes</li>
  <li>dfs.hosts[.exlcude] to allow/deny clients</li>
</ul>

<h3 id="client">Client:</h3>

<ul>
  <li>Use Java libs or command line</li>
  <li>libhdfs c library lacks features and has memory leaks (and FUSE interface uses it)</li>
  <li>Client only contacts NN for metadata</li>
  <li>Client keeps distance-ranked list of block locations for data reads</li>
  <li>Client maintains write queues: data queue and ack queue (writes three times, can’t forget request until all three are ack’d).</li>
  <li>First datanode in write takes responsibility for pass-down-the-line write requests rather than having client spray data at all 3/n data nodes expected to write.</li>
</ul>

<p>Can’t seek and write, nor append. So you create new each time.</p>

<h3 id="hdfs-operator-utilities">HDFS Operator Utilities</h3>

<p>Safe mode</p>

<ul>
  <li>Loads image file, applies edit log, creates new (empty) edit log</li>
  <li>Datanodes send blocklists to NN</li>
  <li>NN uses this during startup, will only service metadata reads while in safe mode</li>
  <li>Exits safe mode after 99.9% of blocks have reported in (configurable); only one replica of block must be known (can rereplicate)</li>
</ul>

<p>FS Check (hadoop fsck)</p>

<ul>
  <li>Just talks to NN to look at metadata</li>
  <li>Looks for minimally rep’d, over/under rep’d blocks</li>
  <li>Identify missing replicas and rereplicate, blocks with 0 replicas (corrupt files)</li>
  <li><code>hadoop fsck /path/to/file -files -blocks</code> to determine blocks for file</li>
  <li>Run ~1 hr in production, store output</li>
</ul>

<p>dfsadmin</p>

<ul>
  <li>admin quotas</li>
  <li>add/remove datanodes</li>
  <li>ckpoint fs image</li>
  <li>monitor/manage fs upgrade</li>
</ul>

<p>DataBlockScanner</p>

<ul>
  <li>cksum local blocks (with bandwidth throttling)</li>
  <li>Runs ~3 weeks (configurable)</li>
</ul>

<p>Balancer</p>

<ul>
  <li>goes thru cluster, makes disk utilization scores per datanode</li>
  <li>rebalances if nodes are more than +/- 10% (with throttling)</li>
</ul>

<p>Archive Tool</p>

<ul>
  <li>HAR file: like tar file, many entries in one HDFS namespace</li>
  <li>Makes two index files and many part files (hopefully less than # of files you’re har’g)</li>
  <li>Index files are used for lookup into part files</li>
  <li>Doesn’t support compression and are W1RM.</li>
</ul>

<p>distcp</p>

<ul>
  <li>Move large amounts of data in parallel</li>
  <li>Implemented as MapReduce with no reducers</li>
  <li>Can move data between data centers with this; can also saturate the network pipe</li>
</ul>

<p>Quotas</p>

<ul>
  <li>apply to directories, not users or groups</li>
  <li>namespace quotas constrain your use of the NN resources</li>
  <li>diskspace quotas constrain your use of the datanodes’ resources</li>
  <li>No defaults (can’t make new directories pick them up)</li>
</ul>

<p>Users, Groups, Permissions</p>

<ul>
  <li>Relatively new</li>
  <li>Very UNIXy</li>
  <li>Executable bit means nothing on file</li>
  <li>Need write on dir to add/remove files</li>
  <li>need exec on dir to access child dirs</li>
  <li>identity of NN process superuser</li>
</ul>

<p>Audit logs</p>

<ul>
  <li>Not on by default, but useful for security</li>
</ul>

<p>Topology</p>

<ul>
  <li>Uses to compute distance measures for replication</li>
  <li>Node, Rack, Core Switch</li>
  <li>Some work to infer from IP</li>
</ul>

<p>Web UIs</p>

<ul>
  <li>There are many</li>
  <li>NN @ port 50070: /metrics /logLevel /stacks</li>
  <li>2NN @ port 50090</li>
  <li>Datanode @ port 50075</li>
</ul>

<p>HFDS Proxy: http server access for non-HDFS clients</p>

<p>ThriftFS: thrift server for non-HDFS clients</p>

<p>Trash:</p>

<ul>
  <li>Helps recover from bad rm’s (indavertent rm -rf happened on FB cluster)</li>
</ul>

<p>Common Problems</p>

<ul>
  <li>Disk capacity: crank up reserved space, keep close eye on space, watch hadoop logfiles</li>
  <li>Slow disks which aren’t yet dead: can’t see as fail, but you have to watch</li>
  <li>NIC goes out of gig-E mode</li>
  <li>ckpoint and backup data: keep an eye on 2NN node, watch NN edit log size</li>
  <li>check NFS mount for shared NN data structure</li>
  <li>Long writes (&gt; 1 hr) can see things get freaky; break them down</li>
  <li>HDFS layoutVersion upgrades are scary</li>
  <li>Many small files can consume namespace: keep an eye on consumption</li>
</ul>

<p>Turn on fairshare schedulers (Cloudera rus it out of the box)</p>

<p>Use distributed cache to send common libs to all nodes</p>

<p>JobControl: good way to express job depedencies</p>

<p>Run canary jobs (sort, dfs write) to test functional status</p>

<p>Upgrades are scary. This will be less true as it reaches 1.0</p>

<p>One admin can easily carry a medium (100-node) cluster. Most activity is around commission/decommission.</p>

<p>Try not to lose more than N nodes, where N is your replication factor. You could hit the jackpot on those being the only three replicas of some needed block.</p>


    <hr>
    <div class="pagination btn-group">
      
        <a class="btn prev" href="/2009/06/liveblog-intro-to-managed-infrastructure-with-puppet.html" title="LiveBlog: Intro to Managed Infrastructure with Puppet">&larr; Previous</a>
      
        <a class="btn" href="/archive.html">Archive</a>
      
        <a class="btn next" href="/2009/06/liveblog-surviving-the-2008-elections-at-dailykoscom.html" title="LiveBlog: Surviving the 2008 Elections at DailyKos.com">Next &rarr;</a>
      
    </div>
    <hr>
    


  <div id="disqus_thread"></div>
<script type="text/javascript">
    
    
    var disqus_shortname = 'geekdaily'; // required: replace example with your forum shortname
    
    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">blog comments powered by <span class="logo-disqus">Disqus</span></a>




  </div>
  
  <div class="span4">
    <section>
      <h4>Published</h4>
      <div class="date"><span>22 June 2009</span></div>
      
    </section>
    
      <section>
        <h4>Categories</h4>
        
      </section>
         
             
  </div>
</div>


        </div>
      </div> <!-- /container -->

      <div class="footer-push"></div>
    </div><!--/.page-wrap -->

    <footer>
      <div class="container">
        <p>&copy; 2015 Jim Meyer
          with help from <a href="http://jekyllbootstrap.com" target="_blank" title="The Definitive Jekyll Blogging Framework">Jekyll Bootstrap</a>
          and <a href="http://github.com/dhulihan/hooligan" target="_blank">The Hooligan Theme</a>
        </p>
      </div>
    </footer>

    <script src="//ajax.googleapis.com/ajax/libs/jquery/1.7.2/jquery.min.js"></script>
    <script>window.jQuery || document.write('<script src="/assets/themes/hooligan/js/jquery.min.js"><\/script>')</script>
    <script src="/assets/themes/hooligan/bootstrap/js/bootstrap.min.js"></script>

    




  <script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-225723-36']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>



  </body>
</html>

